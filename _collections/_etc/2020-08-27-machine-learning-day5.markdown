---
layout: post
title:  "생활코딩 : 머신러닝 야학 1. 6"
date:   2020-08-26 15:53:33 +0830
image: https://images.unsplash.com/photo-1495592822108-9e6261896da8?ixid=MnwxMjA3fDB8MHxzZWFyY2h8M3x8bWFjaGluZSUyMGxlYXJuaW5nfGVufDB8fDB8fA%3D%3D&ixlib=rb-1.2.1&auto=format&fit=crop&w=500&q=60
rating: 5
---

###### DAY 5 : ~ 강화학습 까지

​

##### 비지도학습


비지도학습은 **군집화Clustering**, **변환Transform**, **연관Association** 세 가지로 이루어져 있다.   


<br>​

###### 군집화 Clustering

<br>

**군집화는 비슷한 것들을 찾아 그룹을 만드는 것.** 분류와는 다르다. 그룹을 만드는 것은 군집화. 그룹을 만들고 나서는 적당한 곳에 위치시키게 되는데 이것이 분류다. **분류는 어떤 대상이 어떤 그룹에 속하는지 판단하는 것이다.**  

​<br>

군집Cluster을 만드는 것을 군집화Clustering. **좌표평면**으로 군집을 만들 수 있다.  


행과 열이 기하급수적으로 늘어난다면 사람이 판단하여 그리기 어려운 일이 된다. 또한 축이 x,y축 이상으로 늘어나게 되면 평면에 그려 파악할 수 없기 때문에 머신러닝의 군집화를 이용한다.  
군집화는 서로 가까운 관측치를 찾아주는 머신러닝의 기법이다. 좌표상에서 가깝다는 것은 데이터가 서로 비슷하다는 의미와 같다.  

​

비슷한 행을 그룹화 하는 것이 군집화  
<br>


###### 연관규칙학습 Association rule learning


​

연관의 전체 이름은 연관규칙학습이다. 일명 **장바구니 학습.** 연관성을 파악할 수 있다면 구입할 가능성이 높은 상품을 추천할 수 있다.  
판매하는 상품의 수와 서비스를 이용하는 고객의 수가 많으면 이런 연관성을 찾는 것은 매우 어렵다. 이럴 때 머신러닝의 비지도학습 - 연관규칙 학습을 이용할 수 있다. 동영상 추천, 상품 추천, 검색어 추천 등이 있다.  

<br>

특성을 그룹화 시키는 것 연관규칙학습   

​

​

**관측치(행)를 그룹핑 해주는 것 -> 군집화**<br>

**특성(열)을 그룹핑 해주는 것 -> 연관규칙**
<br>


<br>

###### 비지도학습 정리

​

**비지도학습과 지도학습의 차이점**

<br>
​

비지도학습은 탐험적이고 미지의 세계를 파악하는 것이다. 데이터들의 성격을 파악하려고 하며 독립변수와 종속변수의 구분이 중요하지 않다.     

지도학습은 역사적인 성격을 가지고 과거의 원인과 결과를 바탕으로 현재 원인이 발생하였을 때, 어떤 결과를 초래하는지 추측하는 것이 목적으로 독립변수와 종속변수가 매우 중요하다.   


내가 하는 말 중 긍정적인 말이 많다면 나는 긍정적인 사람이다. 내가 사용하는 물건들 중 컴퓨터에 관련된 것이 많으면 내가 컴퓨터와 관련있는 사람이다. 이렇게 비지도학습 중 군집화와 연관을 놓고 봤을 때는 데이터의 성격을 파악하는 작업은 결국 비슷한 것은 모으고 다른 것은 떨어뜨리는 그룹핑을 하는 것이다. 비지도 학습은 데이터를 정리정돈 해서 표에 담긴 데이터의 성격을 파악하는 것이 중요한 목적이다.    

​<br>

###### 변환

​

**데이터 차원 축소 Data dimendionality reduction** 특성이 많은 고차원 데이터를 특성의 수를 줄여서 저차원으로 감소 시켜 꼭 필요한 특징들을 포함한 데이터로 표현하는 방법. 입력된 데이터를 사람이나 머신러닝에 적용이 가능하도록 반드시 필요한 특징만을 추출한다.    

​

기타 등등이 있는 것 같은데 파이썬 내용들이 많아서 일단 여기까지   

<br>


###### 강화학습

​
**강화학습 Reinforcement learning**


​

강화학습의 핵심은 **일단 해보는 것.** 지도학습이 배움이라면 강화학습은 일단 해보는 것으로 실력을 키우는 것.  
행동의 결과가 유리한 것이면 상, 불리한 것이면 벌을 받는 것인데 이 과정을 수없이 반복하면 더 많은 보상을 받을 수 있는 더 좋은 답을 찾아낼 수 있다는 것이 강화학습의 기본적인 아이디어이다.   

​

게임의 실력을 키우는 것도 강화학습과 비슷하다.   

​

우선 게임은 게이머에게 보여지는 화면이 필요하고, 게이머가 필요하다.  
게이머는 현재의 상태를 관찰해야 하며 관찰의 결과에 따라서 게임을 조작하는 행동을 해야 하고, 관찰과 조작을 하려면 판단력이 필요하다. 

​

게임은 게이머에게 현재 상태를 보여준다. 캐릭터와 장애물의 위치를 알려준다. 그리고 현재의 점수도 보여주는데, 점수가 높아지는 것이 상이고 장애물에 부딪히는 것이 벌이다. 관찰의 결과에 따라 어떤 상태에서 어떻게 행동해야 더 많은 상을 받고, 벌을 덜 받게 되는지 알게된다.   
판단력이 강화되는 것이다. 판단에 따라 행동하고 행동은 게임에게 변화를 주게 된다. 이 과정을 반복하면 판단력이 강화된다.

상태(화면) - 게이머가 상/벌에 관한 or 현재 캐릭터와 장애물 위치 관찰- 판단력 강화 - 판단 - 행동 - 상태 변화 - 관찰 - 강화 - 판단 - 행동 … 

<br>
​

배우지 않고도 잘하게 되는 많은 일들이 이러한 루틴을 따라간다.  
이 루틴의 명칭들을 머신러닝에서 사용하는 명칭으로 바꾸면    


환경 - 에이전트가 보상 or 현재 상태 관찰- 정책 강화 - 정책 - 행동 - 환경 변화 - 관찰 …

<br>
​

*강화학습 예제*



https://www.youtube.com/watch?v=VMp6pq6_QjI  

강화학습을 이용해서 자동차의 주차능력을 향상시키는 예제입니다.   

https://youtu.be/kopoLzvh5jY  

시뮬레이션 환경을 이용한 숨바꼭질 강화학습 영상입니다.  

https://youtu.be/QilHGSYbjDQ   

팩맨의 게임능력을 향상시키는 예제입니다.  

https://youtu.be/ZhsEKTo7V04  

강화학습을 통해 로봇팔이 문 여는 방법을 터득하는 영상입니다.  

https://www.youtube.com/watch?v=Aut32pR5PQA  

2D 시뮬레이터 상에서 강화학습을 이용해 자율주행 기능을 구현하는 영상입니다.  

https://www.youtube.com/watch?v=WSW-5m8lRMs&t=357s  

인공신경망과 강화학습을 이용해 플래피 버드 게임을 하는 인공지능을 만드는 영상입니다.  

 

​

​

​

​